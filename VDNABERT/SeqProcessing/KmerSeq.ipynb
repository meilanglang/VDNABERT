{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logbook\n",
    "import re\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from attic_util import util\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import logbook\n",
    "\n",
    "#DNA sequence processing\n",
    "class SeqGenerator:\n",
    "    def __init__(self, filenames, nb_epochs, seqlen_ulim=250):\n",
    "        self.filenames = filenames\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.seqlen_ulim = seqlen_ulim\n",
    "        self.logger = logbook.Logger(self.__class__.__name__)\n",
    "        self.logger.info('Number of epochs: {}'.format(nb_epochs))\n",
    "\n",
    "    def filehandle_generator(self):\n",
    "        for curr_epoch in range(self.nb_epochs):\n",
    "            for filename in self.filenames:\n",
    "                #print(filename)\n",
    "                with open(filename) as file:\n",
    "                    self.logger.info('Opened file: {}'.format(filename))\n",
    "                    self.logger.info('Memory usage: {} MB'.format(util.memory_usage()))\n",
    "                    self.logger.info('Current epoch: {} / {}'.format(curr_epoch + 1, self.nb_epochs))\n",
    "                    #print(file)\n",
    "                    yield file\n",
    "                    \n",
    "\n",
    "    def generator(self, rng):\n",
    "        for fh in self.filehandle_generator():\n",
    "            print(fh)\n",
    "            # SeqIO takes twice as much memory than even simple fh.readlines()\n",
    "            for seq_record in SeqIO.parse(fh, \"fasta\"):\n",
    "                whole_seq = seq_record.seq\n",
    "                self.logger.info('Whole fasta seqlen: {}'.format(len(whole_seq)))\n",
    "                curr_left = 0\n",
    "                while curr_left < len(whole_seq):\n",
    "                    seqlen = rng.randint(200, self.seqlen_ulim)\n",
    "                    segment = seq_record.seq[curr_left: seqlen + curr_left]\n",
    "                    curr_left += seqlen\n",
    "                    self.logger.debug('input seq len: {}'.format(len(segment)))\n",
    "                    yield segment\n",
    "                    #print(segment)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "class SeqFragmenter:\n",
    "    \"\"\"\n",
    "    Split a sequence into small sequences based on some criteria, e.g. 'N' characters\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_acgt_seqs(self, seq):\n",
    "        return remove_empty(re.split(r'[^ACGTacgt]+', str(seq)))\n",
    "\n",
    "def remove_empty(str_list):\n",
    "    return filter(bool, str_list)  # fastest way to remove empty string\n",
    "\n",
    "\n",
    "class SlidingKmerFragmenter:\n",
    "    \"\"\"\n",
    "    Slide only a single nucleotide\n",
    "    \"\"\"\n",
    "    def __init__(self, k_low, k_high):\n",
    "        self.k_low = k_low\n",
    "        self.k_high = k_high\n",
    "    \n",
    "    def apply(self, rng, seq):\n",
    "        return [seq[i: i + rng.randint(self.k_low, self.k_high + 1)] for i in range(len(seq) - self.k_high + 1)]    \n",
    "\n",
    "'''\n",
    "class DisjointKmerFragmenter:\n",
    "    \"\"\"\n",
    "    Split a sequence into kmers\n",
    "    \"\"\"\n",
    "    def __init__(self, k_low, k_high):\n",
    "        self.k_low = k_low\n",
    "        self.k_high = k_high\n",
    "\n",
    "    @staticmethod\n",
    "    def random_chunks(rng, li, min_chunk, max_chunk):\n",
    "        \"\"\"\n",
    "        Both min_chunk and max_chunk are inclusive\n",
    "        \"\"\"\n",
    "        it = iter(li)\n",
    "        while True:\n",
    "            head_it = islice(it, rng.randint(min_chunk, max_chunk + 1))\n",
    "            nxt = '' . join(head_it)\n",
    "\n",
    "            # throw out chunks that are not within the kmer range\n",
    "            if len(nxt) >= min_chunk:\n",
    "                yield nxt\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    def apply(self, rng,seq):\n",
    "        seq = seq[rng.randint(self.k_low):]  # randomly offset the beginning to create more variations\n",
    "        #print(seq)\n",
    "        return list(DisjointKmerFragmenter.random_chunks(rng, seq, self.k_low, self.k_high))\n",
    "'''\n",
    "\n",
    "class SeqMapper:\n",
    "    def __init__(self, use_revcomp=True):\n",
    "        self.use_revcomp = use_revcomp\n",
    "\n",
    "    def apply(self,seq): \n",
    "        seq = seq.lower()\n",
    "        return seq\n",
    "\n",
    "\n",
    "class Histogram:\n",
    "    def __init__(self):\n",
    "        self.kmer_len_counter = Counter()\n",
    "        self.nb_kmers = 0\n",
    "        self.logger = logbook.Logger(self.__class__.__name__)\n",
    "\n",
    "    def add(self, seq):\n",
    "        \"\"\"\n",
    "        seq - array of k-mer string\n",
    "        \"\"\"\n",
    "        for kmer in seq:\n",
    "            self.kmer_len_counter[len(kmer)] += 1\n",
    "            self.nb_kmers += 1\n",
    "\n",
    "    def print_stat(self, fptr):\n",
    "        for kmer_len in sorted(self.kmer_len_counter.keys()):\n",
    "            self.logger.info('Percent of {:2d}-mers: {:3.1f}% ({})'.format(\n",
    "                kmer_len,\n",
    "                100.0 * self.kmer_len_counter[kmer_len] / self.nb_kmers,\n",
    "                self.kmer_len_counter[kmer_len],\n",
    "            ))\n",
    "\n",
    "        total_bps = sum([l * c for l, c in self.kmer_len_counter.items()])\n",
    "        self.logger.info('Number of base-pairs: {}'.format(total_bps))\n",
    "\n",
    "        \n",
    "        \n",
    "class KmerSeqIterable:\n",
    "    def __init__(self,rand_seed,seq_generator, mapper, seq_fragmenter, kmer_fragmenter,histogram):\n",
    "        self.logger = logbook.Logger(self.__class__.__name__)\n",
    "        self.seq_generator = seq_generator\n",
    "        self.mapper = mapper\n",
    "        self.kmer_fragmenter = kmer_fragmenter\n",
    "        self.seq_fragmenter = seq_fragmenter\n",
    "        self.histogram = histogram\n",
    "        self.rand_seed = rand_seed\n",
    "        self.iter_count = 0\n",
    "   \n",
    "    def __iter__(self):\n",
    "        self.iter_count += 1\n",
    "        rng = np.random.RandomState(self.rand_seed)\n",
    "        for seq in self.seq_generator.generator(rng):\n",
    "            seq = self.mapper.apply(seq)\n",
    "            acgt_seq_splits = list(self.seq_fragmenter.get_acgt_seqs(seq))\n",
    "            self.logger.debug('Splits of len={} to: {}'.format(len(seq), [len(f) for f in acgt_seq_splits]))\n",
    "            for acgt_seq in acgt_seq_splits:\n",
    "                #print(acgt_seq)\n",
    "                kmer_seqs = self.kmer_fragmenter.apply(rng, acgt_seq)# list of strings\n",
    "                if len(kmer_seqs) > 0:\n",
    "                    if self.iter_count == 1:\n",
    "                        # only collect stats on the first call\n",
    "                        self.histogram.add(kmer_seqs)\n",
    "                    #yield kmer_seq\n",
    "                    #print(kmer_seqs)\n",
    "                \n",
    "                #print(kmer_seqs)\n",
    "                count=0\n",
    "                for kmer in kmer_seqs:\n",
    "                    with open ('test.txt', mode = 'a+',encoding='utf-8') as f:# write to file\n",
    "                        if count<len(kmer_seqs)-1:\n",
    "                            f.write(kmer + ' ')\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            f.write(kmer)\n",
    "                            f.write('\\r\\n')\n",
    "                #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object SeqGenerator.generator at 0x7f9d4791d9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epochs=1\n",
    "path = '/home/langmei/notebook/study_software/pro_bert_input/inputs/test'\n",
    "os.chdir(path)\n",
    "filenames = os.listdir()\n",
    "#print(filenames)\n",
    "kmer_segment= SeqGenerator(filenames,nb_epochs)\n",
    "rand_seed=7\n",
    "rng=rng = np.random.RandomState(rand_seed)\n",
    "kmer_segment.generator(rng)\n",
    "kmer_fragmenter = SlidingKmerFragmenter(3, 8)\n",
    "#kmer_fragmenter = DisjointKmerFragmenter(3, 8)\n",
    "histogram = Histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " kmer_seq_iterable = KmerSeqIterable(\n",
    "        rand_seed,\n",
    "        SeqGenerator(filenames, nb_epochs),\n",
    "        SeqMapper(),\n",
    "        SeqFragmenter(),\n",
    "        kmer_fragmenter,\n",
    "        histogram\n",
    " )\n",
    "\n",
    "kmer_seq_iterable.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
